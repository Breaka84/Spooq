name: Tests Python 3.8

on:
  push:
    branches: [ master ]

jobs:
  push_to_master:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        include:
          # Spark 3.1
          - pyspark-version: 3.1.3
            pip-packages: "pyspark==3.1.3 delta-spark==1.0.1"
          # Spark 3.2
          - pyspark-version: 3.2.4
            pip-packages: "pyspark==3.2.4 delta-spark==2.0.2"
          # Spark 3.3
          - pyspark-version: 3.3.4
            pip-packages: "pyspark==3.3.4 delta-spark==2.3.0"
          # Spark 3.4
          - pyspark-version: 3.4.0
            pip-packages: "pyspark==3.4.0 delta-spark==2.4.0"
          - pyspark-version: 3.4.1
            pip-packages: "pyspark==3.4.1 delta-spark==2.4.0"
          - pyspark-version: 3.4.2
            pip-packages: "pyspark==3.4.2 delta-spark==2.4.0"
          # Spark 3.5
          - pyspark-version: 3.5.0
            pip-packages: "pyspark==3.5.0 delta-spark==3.0.0"
          - pyspark-version: 3.5.1
            pip-packages: "pyspark==3.5.1 delta-spark==3.1.0"
    steps:
    - uses: actions/checkout@v2
    - name: Set up Java 1.8
      uses: actions/setup-java@v1
      with:
        java-version: '8'
    - name: Set up Python 3.8
      uses: actions/setup-python@v2
      with:
        python-version: 3.8
    - name: Install pipenv
      run: pip install pipenv
    - name: Run tests with Pyspark ${{ matrix.python-version }}
      env:
        PYSPARK_VERSION_NUMBER: ${{ matrix.pyspark-version }}
        PIP_PACKAGES: ${{ matrix.pip-packages }}
      working-directory: ./tests
      run: |
        echo "Installing Pyspark $PYSPARK_VERSION_NUMBER from pip package $PIP_PACKAGES"
        pipenv install --dev
        pipenv install $PIP_PACKAGES
        pipenv run pytest
